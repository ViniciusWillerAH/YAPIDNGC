{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook __main__.ipynb to script\n",
      "[NbConvertApp] Writing 18146 bytes to __main__.py\n",
      "/bin/bash: del: command not found\n",
      "/bin/bash: move: command not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if __file__ != '__main__.py': \n",
    "        debug = False\n",
    "except: \n",
    "    debug = True\n",
    "    !jupyter nbconvert --to script __main__.ipynb\n",
    "    !del app.py\n",
    "    !move __main__.py app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(':memory:')\n",
    "# db = sqlite3.connect( config[\"STORAGE\"] + r\"\\STORAGE.db\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701218838.1137135"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time , datetime\n",
    "_ScriptStartAt = time.time()\n",
    "now = lambda:datetime.datetime.now().strftime(\"%Y%m%d%H%M%S_%f\")\n",
    "\n",
    "_ScriptStartAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"STORAGE\":\".\"   # WHERE ALL HASH FILES GONNA BE SAVED\n",
    "    # \"STORAGE\":\"\\\\\\\\?\\\\Volume{17b24389-ad3f-48b8-b5bd-553b6a38e726}\\\\STORAGE\", # WHERE ALL HASH FILES GONNA BE SAVED\n",
    "    # \"INDEX.db\":\"W:/STORAGE/index.sqlite3\" # WHERE ALL HISTORY WILL BE REMEMBERED IN SHITSTORM SHITSHOW CRAP HAPPENS\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Backup - Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn2stdout(cmd):\n",
    "    if type(cmd) == bytes:\n",
    "        cmd = cmd.decode()\n",
    "\n",
    "    import subprocess,sys\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout=bytes()\n",
    "    stderr=bytes()\n",
    "\n",
    "    while process.poll() == None or len(out) != 0:\n",
    "        out = process.stdout.readline(1)\n",
    "        stdout += out\n",
    "        out = process.stderr.readline(1)\n",
    "        stderr += out\n",
    "    return stdout , stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trycatch(func,errfunc):\n",
    "    try:\n",
    "        return func()\n",
    "    except Exception as e:\n",
    "        if errfunc:\n",
    "            return errfunc(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "class crc32(object):\n",
    "    name = 'crc32'\n",
    "    digest_size = 4\n",
    "    block_size = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__digest = 0\n",
    "\n",
    "    def update(self, arg):\n",
    "        self.__digest = zlib.crc32(arg, self.__digest) & 0xffffffff\n",
    "        \n",
    "    def digest(self):\n",
    "        return list((self.__digest).to_bytes(4, byteorder='big'))\n",
    "\n",
    "    # def digest(self):\n",
    "    #     # return '{:08x}'.format(self.__digest)\n",
    "    #     return list(self.__digest.to_bytes(4, byteorder='big'))\n",
    "\n",
    "\n",
    "# Now you can define hashlib.crc32 = crc32\n",
    "import hashlib\n",
    "hashlib.crc32 = crc32\n",
    "\n",
    "class length():\n",
    "    def __init__(self):\n",
    "        self.size=0\n",
    "    def update(self,data):\n",
    "        self.size+=len(data)\n",
    "    def digest(self):\n",
    "        return list(self.size.to_bytes(8, byteorder='big'))\n",
    "\n",
    "class sumAll():\n",
    "    def __init__(self):\n",
    "        self.size=0\n",
    "    def update(self,data):\n",
    "        self.size+=sum(list(data))\n",
    "    def digest(self):\n",
    "        return list(self.size.to_bytes(10, byteorder='big'))\n",
    "\n",
    "class copyFile():\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            if tempDir is None: return\n",
    "            import datetime\n",
    "            import random\n",
    "            # currentDT = datetime.datetime.now()\n",
    "            # self.fname =  \"f:\\\\temp\\\\\" + currentDT.strftime(\"%Y%m%d%H%M%S_%f_\")+str( random.randint(0,99999) ).zfill(5)+'.tmp'\n",
    "            self.fname =  tempDir + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_%f_\")+str( random.randint(0,99999) ).zfill(5)+'.tmp'\n",
    "            os.makedirs( os.path.dirname( self.fname ) ,exist_ok=True )\n",
    "            self.fopen = open(self.fname , \"wb\" )\n",
    "        except:\n",
    "            try:self.fopen.close()\n",
    "            except:None\n",
    "            raise Exception(self.fname,\" Path Cannot be written. \")\n",
    "    def update(self,data):\n",
    "        if tempDir is None: return\n",
    "        try:\n",
    "            self.fopen.write(data)\n",
    "        except:\n",
    "            self.fopen.close()\n",
    "            raise\n",
    "        None\n",
    "    def digest(self):\n",
    "        if tempDir is None: return\n",
    "        self.fopen.close()\n",
    "        return self.fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_file(filename,tempDir=config[\"STORAGE\"] + \"\\\\temp\\\\\"):\n",
    "    import os, os.path as path\n",
    "    assert path.isfile(filename) , \"File not found for hash operation\"\n",
    "\n",
    "    hashes = [ #### make a hash object\n",
    "\n",
    "        # [ 'blake2b' , hashlib.blake2b() ],\n",
    "        # [ 'blake2s' , hashlib.blake2s() ],\n",
    "        # [ 'sha224' , hashlib.sha224() ],\n",
    "        # [ 'sha384' , hashlib.sha384() ],\n",
    "        # [ 'sha3_224' , hashlib.sha3_224() ],\n",
    "        # [ 'sha3_256' , hashlib.sha3_256() ],\n",
    "        # [ 'sha3_384' , hashlib.sha3_384() ],\n",
    "        # [ 'sha3_512' , hashlib.sha3_512() ],\n",
    "        # [ 'sha512' , hashlib.sha512() ],\n",
    "        # [ 'shake_128' , hashlib.shake_128() ],\n",
    "        # [ 'shake_256' , hashlib.shake_256() ],\n",
    "        [ 'crc32' , hashlib.crc32() ] ,\n",
    "        [ 'md5' , hashlib.md5() ] ,\n",
    "        [ 'sha1' , hashlib.sha1() ] ,\n",
    "        [ 'sha256' , hashlib.sha256() ] ,\n",
    "        [ \"sumAll\" , sumAll() ] ,\n",
    "        [ \"length\" , length() ] ,\n",
    "        [ \"copyFPath\" , copyFile() ],\n",
    "\n",
    "    ]\n",
    "\n",
    "    with open(filename,'rb') as file:   ### open file for reading in binary mode\n",
    "        chunk = 0\n",
    "        while chunk != b'':\n",
    "            chunk = file.read(1024*4 )  ### read file in chunks and update hash\n",
    "            # h_sha256.update(chunk) ### old code. below there is a new way to do this\n",
    "            for _,hash2 in hashes:\n",
    "                hash2.update( chunk )\n",
    "\n",
    "    hashResult = []\n",
    "    for hashName , hashFunc in hashes:  ### return the hex digest of each hash engine\n",
    "        tmp = hashFunc.digest()\n",
    "        try:\n",
    "            hashResult.append( [ hashName , \"\".join([ (\"0\"+hex(x)[2:])[-2:] for x in list( tmp ) ] ) ] ) ### convert to hex\n",
    "        except:\n",
    "            hashResult.append( [ hashName , tmp ] ) ### save as it is\n",
    "    return hashResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: wmic: not found\n",
      "/bin/sh: 1: mountvol: not found\n",
      "/bin/sh: 1: net: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re,os\n",
    "def getAllDisksMount():\n",
    "    # disksList = re.findall(r\"(\\\\\\\\?\\\\.*\\{[0-9a-f]{8}-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{12}\\}\\\\)\",os.popen(\"mountvol\").read(),re.MULTILINE) ## \"wmic VOLUME get DeviceID\"\n",
    "    disksList = re.findall(r\"(\\\\\\\\?\\\\.*\\{[0-9a-f]{8}-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{12}\\}\\\\)\",os.popen(\"wmic VOLUME get DeviceID\").read(),re.MULTILINE)\n",
    "    letters = [ chr(x) + \":\\\\\" for x in range(65,90) if os.path.exists( chr(x) + \":\\\\\" ) ]\n",
    "\n",
    "    for vol , letter in re.findall(r\"(\\\\\\\\?\\\\.*\\{[0-9a-f]{8}-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{4}\\-[0-9a-f]{12}\\}\\\\)\\n\\s+(.*)\",os.popen(\"mountvol\").read(),re.MULTILINE):\n",
    "        try:\n",
    "            if vol in disksList:\n",
    "                letters.remove( letter[:2]+\"\\\\\" )\n",
    "        except: None\n",
    "\n",
    "    for letter in re.findall(r\"\\nOK\\s+([a-zA-Z]:)\\s+\\\\\\\\.+?\\s+Microsoft Windows Network\" , os.popen(\"net use\").read() ):\n",
    "        letters.remove(letter+\"\\\\\")\n",
    "\n",
    "    return disksList + letters\n",
    "getAllDisksMount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir(path):\n",
    "    try: tmp = [ os.path.join(path,x) for x in os.listdir(path) ] \n",
    "    except: tmp = []\n",
    "    tmp.sort()\n",
    "    return tmp\n",
    "# listdir = lambda path:[ os.path.join(path,x) for x in os.listdir(path) ] \n",
    "\n",
    "def walkdir(path):\n",
    "    paths = [ path ]\n",
    "    while len(paths) > 0:\n",
    "\n",
    "        path = paths.pop(0)\n",
    "\n",
    "        if path.lower() == \"SHA256_SHA1_MD5\".lower():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            os.readlink(path)\n",
    "            yield path\n",
    "            continue\n",
    "        except:\n",
    "            None\n",
    "\n",
    "        try:\n",
    "            if os.path.isdir(path):\n",
    "                if os.path.basename(path).lower() in [ path_x.lower() for path_x in [\"DUMP\",\"Sysmon\",\".ipynb_checkpoints\",\"CacheManager\",\"Steamlibrary\",\"htmlcache\",\"SteamApps\",\"log\",\"temp\",\"tmp\",\"STORAGE\",\"AppCache\",\"cacho\",\"raw\",\"morgue\",\"Cache\",\"cache2\",\"Caches\",\"Code Cache\",\"CacheStorage\",\"Code\",\"D3DSCache\",\"GPUCache\",\"GrShaderCache\",\"INetCache\",\"jumpListCache\",\"optimization_guide_hint_cache_store\",\"ScriptCache\",\"shader-cache\",\"ShaderCache\",\"shadercache\",\"startupCache\",\"$RECYCLE.BIN\",\"System Volume Information\",\"Temporary Internet Files\"] ]:\n",
    "                    continue\n",
    "                paths = [ os.path.join(path,x) for x in os.listdir(path) ] + paths\n",
    "                continue\n",
    "            else:\n",
    "                tmp = path.lower()\n",
    "                if True in [ tmp.endswith( ext.lower() ) for ext in [ \".STORAGETHIS\" , \".tmp\" , \".temp\" , \".log\" , \".ztmp\" , \".evt\" , \".evtx\" , \".dmp\" , \".dump\"  , \".etl\" ] ]:\n",
    "                    continue\n",
    "                yield path\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            None\n",
    "\n",
    "def walkdirs(path):\n",
    "    assert type(path) == list, \"Expected 'list' \"\n",
    "\n",
    "    paths = [ walkdir(x) for x in path ]\n",
    "    x = 0\n",
    "    while True:\n",
    "        try:\n",
    "            yield next( paths[x] )\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except StopIteration:\n",
    "            paths.remove( paths[x] )\n",
    "            x+=-1\n",
    "        except:\n",
    "            if len( paths ) == 0:\n",
    "                return\n",
    "            paths.pop(x)\n",
    "            x+=-1\n",
    "        x+=1\n",
    "        if x >= len( paths ):\n",
    "            x=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaArquivos = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __Worker_Backup():\n",
    "    global status , listaArquivos\n",
    "    status = '{\"result\":\"Initiated\"}'\n",
    "    import random , datetime\n",
    "\n",
    "    fNameBkp = \"Mapping_\" + str(_ScriptStartAt) + \".csv\"\n",
    "    with open( config[\"STORAGE\"] + \"\\\\\"+ fNameBkp,\"ab\" ) as f_io:\n",
    "        filehashed_Count=1\n",
    "        while filehashed_Count !=0: ### in case no files are found, stop the script\n",
    "            filehashed_Count=0\n",
    "            try:\n",
    "                for filePath in walkdirs( [\".\"] ):#getAllDisksMount() ):\n",
    "                    sha256,sha1,md5,stat = None,None,None,None\n",
    "                    try:\n",
    "                        if \"\\\\temp\\\\\"   in  filePath :\n",
    "                            continue\n",
    "                        if \"/temp/\"     in  filePath :\n",
    "                            continue\n",
    "                        stat = os.stat( filePath )\n",
    "                        fileStats = [ [ \"n_fields\" , stat.n_fields ] ,[ \"n_sequence_fields\" , stat.n_sequence_fields ] ,[ \"n_unnamed_fields\" , stat.n_unnamed_fields ] ,[ \"st_atime\" , stat.st_atime ] ,[ \"st_atime_ns\" , stat.st_atime_ns ] ,[ \"st_ctime\" , stat.st_ctime ] ,[ \"st_ctime_ns\" , stat.st_ctime_ns ] ,[ \"st_dev\" , stat.st_dev ] ,[ \"st_file_attributes\" , stat.st_file_attributes ] ,[ \"st_gid\" , stat.st_gid ] ,[ \"st_ino\" , stat.st_ino ] ,[ \"st_mode\" , stat.st_mode ] ,[ \"st_mtime\" , stat.st_mtime ] ,[ \"st_mtime_ns\" , stat.st_mtime_ns ] ,[ \"st_nlink\" , stat.st_nlink ] ,[ \"st_reparse_tag\" , stat.st_reparse_tag ] ,[ \"st_size\" , stat.st_size ] ,[ \"st_uid\" , stat.st_uid ] ]\n",
    "                        fileSize = stat.st_size\n",
    "                        if ( filePath + str(stat.st_ctime_ns) + str(stat.st_mtime_ns) ) in listaArquivos:\n",
    "                            continue\n",
    "\n",
    "                        ### All Green, lets hash the file, then copy it to the backup folder\n",
    "                        \n",
    "                        message = hash_file( filePath )# , tempDir=\"T:\\\\STORAGE\\\\TEMP\\\\\" )\n",
    "                        tmp = [ [ \"filePath\" , filePath ] ] + message + [ [ \"scriptStart\" , _ScriptStartAt ],[ \"hashTimeAt\" , time.time() ] ] + fileStats\n",
    "\n",
    "                        f_io.write( \"*\".join( [ str( x[1] ) for x in tmp ] ).encode() )\n",
    "                        f_io.write( \"\\r\\n\".encode() )\n",
    "\n",
    "                        for varName , Val in message:\n",
    "                            if varName == \"md5\": md5 = Val\n",
    "                            if varName == \"sha1\": sha1 = Val\n",
    "                            if varName == \"sha256\": sha256 = Val\n",
    "                            if varName == \"copyFPath\": copyFPath = Val\n",
    "\n",
    "                        temporarily = copyFPath\n",
    "                        StoragePath = os.path.join( config[\"STORAGE\"] , \"SHA256_SHA1_MD5\" , sha256[0:2] , sha256[2:4] , sha256 + \"_\" + sha1 + \"_\" + md5  )\n",
    "\n",
    "                        os.makedirs( os.path.dirname( StoragePath ) , exist_ok=True )                        \n",
    "                        trycatch( lambda: shutil.movefile( temporarily , StoragePath ) )\n",
    "                        trycatch( lambda: spawn2stdout( 'cmd /c move \"'+temporarily+'\" \"'+StoragePath+'\" ' ) )\n",
    "                        \n",
    "\n",
    "                        try:    listaArquivos.add( ( filePath + str(stat.st_ctime_ns) + str(stat.st_mtime_ns) ) )\n",
    "                        except: listaArquivos.append( ( filePath + str(stat.st_ctime_ns) + str(stat.st_mtime_ns) ) )\n",
    "\n",
    "\n",
    "                        filehashed_Count+=1 ### tell the script that at least one file was hashed\n",
    "                        status = '{\"result\":\"Working\"}'\n",
    "\n",
    "                    except KeyboardInterrupt as Keyb:\n",
    "                        raise\n",
    "                    except Exception as Err:\n",
    "                        if Err.args in [\n",
    "                            ('File not found for hash operation',),\n",
    "                            \n",
    "                            (2 , 'The system cannot find the path specified'),\n",
    "                            (2 , 'The system cannot find the file specified'),\n",
    "                            (2 , 'The network path was not found'),\n",
    "                            \n",
    "                            (13, 'Permission denied'),\n",
    "                            (13, 'Access is denied'),\n",
    "                            (13, 'The device is not ready'),\n",
    "                            \n",
    "                            (22, 'Invalid argument'),\n",
    "                            (22, 'A device which does not exist was specified'),\n",
    "                            (22, 'The file cannot be accessed by the system'),\n",
    "                            (22, 'The symbolic link cannot be followed because its type is disabled'),\n",
    "                            (22, 'An unexpected network error occurred'),\n",
    "                            (22, 'The semaphore timeout period has expired'),                            \n",
    "                        ]:\n",
    "                            continue\n",
    "\n",
    "            except KeyboardInterrupt as Keyb:\n",
    "                status = '{\"result\":\"ERROR_KeyboardInterrupt\"}'\n",
    "                raise\n",
    "            except StopIteration:\n",
    "                status = '{\"result\":\"ERROR_StopIteration\"}'\n",
    "                continue\n",
    "            except Exception as Err:\n",
    "                status = '{\"result\":\"ERROR_Exception\",\"ErroMessage\":\"'+str(Err)+'\"}'\n",
    "                None\n",
    "    status = '{\"result\":\"Done\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = None\n",
    "def __Worker_Backup_START():\n",
    "    global thread1\n",
    "    try:\n",
    "        if not thread1.is_alive():\n",
    "            raise 0\n",
    "        # print(\" Thread is \\033[96m ALREADY \\033[1;0m Running\")\n",
    "        return '{\"result\":\"RunningAlready\"}'\n",
    "    except:\n",
    "        from threading import Thread\n",
    "        thread1 = Thread( target=__Worker_Backup , args=() )\n",
    "        thread1.start()\n",
    "        # print(\" Thread has \\033[95m STARTED \\033[1;0m Running\")\n",
    "        return '{\"result\":\"OK\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Backup - Carregamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"Mapping_1699371619.749871_20231107124020_699131_59895.csv\",\"r\") as file:\n",
    "        Dados = file.readline().split(\"*\")\n",
    "        tmp = ( Dados[0] + Dados[16] + Dados[23] )\n",
    "        try:    listaArquivos.   add( tmp )\n",
    "        except: listaArquivos.append( tmp )\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /usr/local/python/3.10.8/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/codespace/.local/lib/python3.10/site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    %pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor do site - Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app ''\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask , Response , redirect\n",
    "if debug:\n",
    "    app = Flask(\"\")#__name__)\n",
    "else:\n",
    "    app = Flask(__name__)\n",
    "\n",
    "# Main Page\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    return redirect(\"/index.html\", code=302)\n",
    "\n",
    "# Generic Resource\n",
    "get_resource = lambda *argp:\"<html><head/><body><h1> EMPTY </h1></body></html>\"\n",
    "@app.route('/<path:path>')\n",
    "def __get_resource( path ):  # pragma: no cover\n",
    "    global get_resource\n",
    "    return get_resource( path )\n",
    "\n",
    "# Backup Thread Status\n",
    "status = '{\"result\":\"NotStarted\"}'\n",
    "@app.route('/api/v0/status')\n",
    "def __status():  # pragma: no cover\n",
    "    global status\n",
    "    return status\n",
    "\n",
    "# Trigger Backup Thread\n",
    "@app.route('/api/v0/startBackup')\n",
    "def __Worker_Backup_Status( ):  # pragma: no cover\n",
    "    global __Worker_Backup_START\n",
    "    return __Worker_Backup_START()\n",
    "\n",
    "# FileTreeExplorer\n",
    "get_path = lambda *argp:\"<html><head/><body><table/></body></html>\"\n",
    "@app.route('/api/v0/getPath')\n",
    "def __get__pathroot():  # pragma: no cover\n",
    "    global get_path\n",
    "    return get_path( \".\" )\n",
    "@app.route('/api/v0/getPath/<path:path>')\n",
    "def __get__path( path ):  # pragma: no cover\n",
    "    global get_path\n",
    "    return get_path( path )\n",
    "\n",
    "# get the file that was backuped-up in one of the previously backup threads\n",
    "get_filePath = lambda *argp:\"<html><head/><body><table/></body></html>\"\n",
    "@app.route('/api/v0/getPath/<path:path>')\n",
    "def __get__filePath( path ):  # pragma: no cover\n",
    "    global get_filePath\n",
    "    return get_filePath( path )\n",
    "\n",
    "# app.debug = True\n",
    "__main__ = lambda: app.run( host='127.0.0.1' , port=18080 , debug=not debug )\n",
    "\n",
    "if debug:\n",
    "    from threading import Thread\n",
    "    Thread( target=__main__, args=() ).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource( path ):  # pragma: no cover\n",
    "    print(\"###\" , path )\n",
    "    mimetypes = {\n",
    "        \".css\": \"text/css\",\n",
    "        \".html\": \"text/html\",\n",
    "        \".js\": \"application/javascript\",\n",
    "    }\n",
    "    if os.path.exists( path ):\n",
    "        with open( path ) as f_io:\n",
    "            return Response( f_io.read() , mimetype=mimetypes.get( path.split(\".\")[-1] , \"text/html\") )\n",
    "    else:\n",
    "        return Response( status=404 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:18080\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, send_file\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/download')\n",
    "# def download_file():\n",
    "#     local_filename = 'local_file.txt'\n",
    "#     remote_filename = 'remote_file.txt'\n",
    "#     return send_file(local_filename, as_attachment=True, attachment_filename=remote_filename)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_path = lambda *argp:\"<html><head/><body><table/></body></html>\"\n",
    "\n",
    "def __get_path_Backups__():\n",
    "    get_path_Status = 1\n",
    "    def loopableThingy():\n",
    "        get_path_Status = 0\n",
    "        for root, dirs, files in os.walk( config[\"STORAGE\"] + r\"\\SHA256_SHA1_MD5\" ):\n",
    "            for file in files:\n",
    "                yield os.path.join(root, file)\n",
    "\n",
    "\n",
    "    get_path_Status = 2\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_Status = 0\n",
    "def get_path( path ):  # pragma: no cover\n",
    "    if get_path_Status == 0:\n",
    "        from threading import Thread\n",
    "        Thread( target=__get_path_Backups__ ).start()\n",
    "        get_path_Status = 1\n",
    "        return '<table><tr><td>Loading</td></tr></table><script>setTimeout( function(){ document.getElementById(\"buttonUpdate\"); } , 1000 )</script>'\n",
    "    else:\n",
    "        body = \"\"\n",
    "        if get_path_Status == 1:\n",
    "            body += '<h1>A Listagem de arquivos esta incompleta.</h1><p>ainda esta sendo carregada em memoria</p>'\n",
    "        body += '<table><tr><td></td></tr></table>'\n",
    "        body += '<table><tr><td></td></tr></table>'\n",
    "\n",
    "        return body\n",
    "\n",
    "    return \"NOT IMPLEMENTED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.root()\n",
    "# def __HTMLRoot__(ur):\n",
    "    # with open(\"index.html\") as f_io:\n",
    "        # return f_io.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HTMLRoot():\n",
    "    with open(\"index.html\") as f_io:\n",
    "        return f_io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html lang=\"en\">\\n    <head>\\n        <title> SeiLá Backups </title>\\n        <meta charset=\"utf-8\">\\n        <!--<script src=\"https://unpkg.com/htmx.org@1.9.9\"></script>-->\\n        <script>\\n            function getAndReplaceInnerHTML(url, elementId) {\\n                var xhr = new XMLHttpRequest();\\n                xhr.onreadystatechange = function() {\\n                    if (xhr.readyState === XMLHttpRequest.DONE) {\\n                        if (xhr.status === 200) {\\n                            var element = document.getElementById(elementId).innerHTML = xhr.responseText;\\n                        } else {\\n                            console.error(\\'Request failed with status \\' + xhr.status);\\n                        }\\n                    }\\n                };\\n                xhr.open(\\'GET\\', url, true);\\n                xhr.send();\\n            }\\n        </script>\\n        <style>\\n            html {  line-height: 1.15; }\\n            body {  margin: 0; }\\n            * {  box-sizing: border-box;  border-width: 0;  border-style: solid; }\\n            p,li,ul,pre,div,h1,h2,h3,h4,h5,h6,figure,blockquote,figcaption {  margin: 0;  padding: 0; }\\n            #button {  background-color: transparent; }\\n            button,input,optgroup,select,textarea {  font-family: inherit;  font-size: 100%;  line-height: 1.15;  margin: 0; }\\n            button,select {  text-transform: none; }\\n            button,[type=\"button\"],[type=\"reset\"],[type=\"submit\"] {  -webkit-appearance: button; }\\n            a {  color: inherit;  text-decoration: inherit; }\\n            input {  padding: 2px 4px; }\\n            img {  display: block; }\\n        </style>\\n    </head>\\n    <body style=\"height: 100%;width: 100%;display: flex;align-items: center;flex-direction: column;background-color: #ffffff;\">\\n        <header style=\"width: 100%;  height: 50px;  display: flex;  z-index: 100;  align-self: center;  align-items: center;  justify-content: space-between;  background: #000;  color: #fff;\">\\n            <h2 style=\"font-size: 32px;  font-style: normal;  font-weight: 600;  line-height: 45px;\">{{{PageName}}}</h2>\\n            <!--<div style=\"gap: 30px;  flex: 0 0 auto;  display: flex;  align-items: center;  flex-direction: row;  padding-right: 40px;\">-->\\n            <div id=\"tabs\" hx-target=\"#contents\" role=\"tablist\" _=\"on htmx:afterOnLoad set @aria-selected of <[aria-selected=true]/> to false tell the target take .selected set @aria-selected to true\">\\n                <button class=\"navLink\" onclick=\"getAndReplaceInnerHTML(\\'content\\',\\'/api/v0/status\\')\">Status</button>\\n                <button class=\"navLink\" onclick=\"getAndReplaceInnerHTML(\\'content\\',\\'/api/v0/Current\\')\">Current</button>\\n                <button class=\"navLink\" onclick=\"getAndReplaceInnerHTML(\\'content\\',\\'/api/v0/status\\')\">Backups</button>\\n            </div>\\n        </header>\\n        <div id=\"content\" style=\"height: 85vh;overflow-y: scroll;\">\\n            <div style=\"padding: 100px;\">\\n                <div id=\"content\" role=\"tabpanel\" class=\"content\">\\n                    Selecione uma das opções no menu acimas.\\n                </div>\\n            </div>\\n        </div>\\n        <footer style=\"width: 100%;height: auto;display: flex;align-items: center;flex-direction: column;color: #FFF;background: #000;\">\\n            <span>{{{ Footer.text }}}</span>\\n            <div style=\"width: 100%;display: flex;max-width: 600px;align-self: center;align-items: center;flex-direction: row;justify-content: center;\">\\n            <img alt=\"image\" src=\"public/linkedin.svg\">\\n            <img alt=\"image\" src=\"public/instagram.svg\">\\n            <img alt=\"image\" src=\"public/twitter.svg\">\\n            </div>\\n            <span>\\n            Privacy — Terms &amp; Conditions — Code of Conduct © {{{\\n            datetime.year }}} No Rights Reserved\\n            </span>\\n        </footer>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-29 00:47:27,025] ERROR in app: Exception on /api/v0/getPath [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/flask/app.py\", line 1455, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/flask/app.py\", line 869, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/flask/app.py\", line 867, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/flask/app.py\", line 852, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/tmp/ipykernel_51718/1621577518.py\", line 37, in __get__pathroot\n",
      "    return get_path( \".\" )\n",
      "  File \"/tmp/ipykernel_51718/183110928.py\", line 3, in get_path\n",
      "    if get_path_Status == 0:\n",
      "UnboundLocalError: local variable 'get_path_Status' referenced before assignment\n",
      "127.0.0.1 - - [29/Nov/2023 00:47:27] \"GET /api/v0/getPath HTTP/1.1\" 500 -\n",
      "[2023-11-29 00:47:27,026] INFO in _internal: 127.0.0.1 - - [29/Nov/2023 00:47:27] \"\u001b[35m\u001b[1mGET /api/v0/getPath HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "HTMLRoot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
